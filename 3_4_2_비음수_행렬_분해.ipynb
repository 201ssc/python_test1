{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.4.2 비음수 행렬 분해.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3och/E7pGpACaao9MN1Su",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/201ssc/python_test1/blob/main/3_4_2_%EB%B9%84%EC%9D%8C%EC%88%98_%ED%96%89%EB%A0%AC_%EB%B6%84%ED%95%B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ryEAllNL1Rj",
        "outputId": "9166c3de-bcd5-4d1c-b16a-eac04ef5f7ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mglearn\n",
            "  Downloading mglearn-0.1.9.tar.gz (540 kB)\n",
            "\u001b[K     |████████████████████████████████| 540 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mglearn) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.3.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from mglearn) (7.1.2)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.7/dist-packages (from mglearn) (0.11.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from mglearn) (2.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mglearn) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mglearn) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mglearn) (2022.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->mglearn) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->mglearn) (3.1.0)\n",
            "Building wheels for collected packages: mglearn\n",
            "  Building wheel for mglearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mglearn: filename=mglearn-0.1.9-py2.py3-none-any.whl size=582639 sha256=d1d1cab3920828c413b9f7f4d23b6cb6428b89f73ddbaa9c636af73378ba5014\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/17/e1/1720d6dcd70187b6b6c3750cb3508798f2b1d57c9d3214b08b\n",
            "Successfully built mglearn\n",
            "Installing collected packages: mglearn\n",
            "Successfully installed mglearn-0.1.9\n"
          ]
        }
      ],
      "source": [
        "!pip install mglearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import mglearn\n",
        "import matplotlib\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "from sklearn.preprocessing import QuantileTransformer, StandardScaler, PowerTransformer\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import seaborn as sns\n",
        "sns.set(font_scale=3)\n",
        "sns.set(rc = {'figure.figsize':(12,8)})\n",
        "\n",
        "from pandas.core.common import random_state"
      ],
      "metadata": {
        "id": "94ymMoHQL8iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.4.2 비음수 행렬 분해\n",
        "\n",
        "특성뽑아낸다. 비지도 알고리즘, 차원축소에도 사용, 가중치 합으로 각 데이터 포인트 나타냄. PCA와 다르게 NMF는 분산이 적고, 음수가 아닌 성분과 계수값을 찾는다. 즉 주성분과 계수가 모두 0보다 크거나 같아야 한다.\n",
        "\n",
        "\\\n",
        "주로 오디오 트랙과 같이 여러 악기로 이루어진 음악 데이터에 이용한다."
      ],
      "metadata": {
        "id": "VMkTnQRsPNGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mglearn.plots.plot_nmf_illustration()"
      ],
      "metadata": {
        "id": "tOPKc3ZXQPC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NMF를 다루려면 주어진 데이터가 양수인지 확인해야 한다. 다른 말로 원점에서 데이터가 어디에 놓여있는지 알아야 된다는 의미. \n",
        "**그림** 왼쪽은 성분이 2개 오른쪽은 성분이 1개 일때이다. 하나의 성분만 사용한다면 평균으로 향하는 성분을 만들고, 많다면 각 특성 끝에 위치한 포인트를 가르킨다. \n",
        "PCA와 다르게 주성분은 없다. 모든 성분을 동등하게 취급한다. NMF는 무작위로 초기화하기 때문에 난수 생성 초깃값에 따라 결과가 달라진다.\n",
        "\n",
        "\\\n",
        "### 얼굴 이미지에 NMF 적용하기\n",
        "\n",
        "LFW 데이터셋에 NMF를 적용하기\n",
        "NMF 를 사용해 데이터를 재구성하는 데 성분의 개수가 어떤 영향을 주는지 살펴본다."
      ],
      "metadata": {
        "id": "jJEWxxLxRQlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.pylabtools import figsize\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "people = fetch_lfw_people(min_faces_per_person=20, resize=0.7)\n",
        "image_shape = people.images[0].shape\n",
        "\n",
        "mask = np.zeros(people.target.shape, dtype=bool)\n",
        "for target in np.unique(people.target):\n",
        "  mask[np.where(people.target == target)[0][:50]] = 1\n",
        "\n",
        "X_people = people.data[mask]\n",
        "y_people = people.target[mask]\n",
        "X_people = X_people / 255  ## 맞나??\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_people, y_people, stratify=y_people, random_state=0)\n"
      ],
      "metadata": {
        "id": "BV5tXN8xSxON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mglearn.plots.plot_nmf_faces(X_train, X_test[:3], image_shape)"
      ],
      "metadata": {
        "id": "b-r8TvirT8bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA 보다 품질이 조금 떨어짐. PCA는 주성질을 이용하기에 다른 듯함. NMF는 데이터를 인코딩하거나 재구성하는 용도로 사용하기 보단 데이터에 있는 유용한 패턴을 찾는데 활용해야 할듯"
      ],
      "metadata": {
        "id": "Wb3eUuinW7Mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import NMF\n",
        "nmf = NMF(n_components=15, init='nndsvd', random_state=0, max_iter=1000, tol=1e-2)\n",
        "nmf.fit(X_train)\n",
        "X_train_nmf = nmf.transform(X_train)\n",
        "X_test_nmf = nmf.transform(X_test)\n",
        "\n",
        "fig, axes = plt.subplots(3, 5, figsize=(15, 12), subplot_kw={'xticks': (), 'yticks':()})\n",
        "for i, (component, ax) in enumerate(zip(nmf.components_, axes.ravel())):\n",
        "  ax.imshow(component.reshape(image_shape))\n",
        "  ax.set_title('component {}'.format(i))"
      ],
      "metadata": {
        "id": "zFR2ijWAWyIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compn = 3\n",
        "# 4번째 성분으로 정렬하여 처음 10개 이미지를 출력한다.\n",
        "inds = np.argsort(X_train_nmf[:, compn])[::-1]\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 8), subplot_kw={'xticks': (), 'yticks':()})\n",
        "\n",
        "for i, (ind, ax) in enumerate(zip(inds, axes.ravel())):\n",
        "  ax.imshow(X_train[ind].reshape(image_shape))\n",
        "\n",
        "compn = 7\n",
        "# 8번째 성분으로 정렬하여 처음 10개 이미지를 출력한다.\n",
        "inds = np.argsort(X_train_nmf[:, compn])[::-1]\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 8), subplot_kw={'xticks': (), 'yticks':()})\n",
        "\n",
        "for i, (ind, ax) in enumerate(zip(inds, axes.ravel())):\n",
        "  ax.imshow(X_train[ind].reshape(image_shape))\n",
        "\n",
        "# 4 > 오른쪽으로 돌아감\n",
        "# 8 > 왼쪽으로 돌아감\n",
        "\n",
        "# 즉, 패턴 추출\n"
      ],
      "metadata": {
        "id": "ll4tVXe6ZZom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 세 개의 서로다른 입력으로 부터 함성된 신호\n",
        "\n",
        "S = mglearn.datasets.make_signals()\n",
        "plt.figure(figsize=(14,4))\n",
        "plt.plot(S, '-')\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('signal')"
      ],
      "metadata": {
        "id": "NmPf751QbK38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "만약 원본 신호는 볼 수 없고 이 세 개가 섞인 신호만 관찰할 수 있는 상황이다.\n",
        "합쳐진 신호를 분해해 원본 신호를 복원해야 한다.\n",
        "이 신호를 여러방법으로 관찰할 수 있고 각 장치는 일련의 측정 데이터를 제공한다.\n"
      ],
      "metadata": {
        "id": "M8EPujZtce-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 데이터 사용, 100개의 측정 데이터를 만든다.\n",
        "A = np.random.RandomState(0).uniform(size=(100, 3))\n",
        "X = np.dot(S, A.T)\n",
        "print(\"측정 데이터 형태:\", X.shape)"
      ],
      "metadata": {
        "id": "jiEUfvr3c5h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NMF 를 사용 세 개의 신호 복원\n",
        "nmf = NMF(n_components=3, init='nndsvd', random_state=42, max_iter=1000, tol=1e-2)\n",
        "S_ = nmf.fit_transform(X)\n",
        "print(\"복원한 신호 데이터 형태:\", S_.shape)"
      ],
      "metadata": {
        "id": "ReK9NrFIdWe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 비교를 위한 PCA\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=3)\n",
        "H = pca.fit_transform(X)"
      ],
      "metadata": {
        "id": "ss5I49sQd1k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [X, S, S_, H]\n",
        "names = ['measurement signal(3)', 'original signal', 'NMF recover signal', 'PCA recover signal']\n",
        "\n",
        "fig, axes = plt.subplots(4, figsize=(15, 8), gridspec_kw={'hspace': .5}, subplot_kw={'xticks': (), 'yticks':()})\n",
        "\n",
        "for model, name, ax in zip(models, names, axes):\n",
        "  ax.set_title(name)\n",
        "  ax.plot(model[:, :3], '-')"
      ],
      "metadata": {
        "id": "fqYpK38teU8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA 대비 좋은 성능을 냈지만 NMF는 성분 순서가 없음을 유의해야한다.\n",
        "세 커브의 겹쳐진 순서를 보자.\n",
        "그 밖에도 패턴 추출은 / 독립성분분석 ICA / 희소코딩에 관해 설명하고 있는 [scikit-learn 사용자 가이드](https://scikit-learn.org/stable/modules/decomposition.html) 를 참고하자"
      ],
      "metadata": {
        "id": "NAFNPPUUghl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4.3 t-SNE를 이용한 매니폴드 학습\n",
        "데이터를 산점도로 시각화 할 수 있다는 이점으로 PCA가 종종 데이터 변화에 가장 먼저 시도해볼 만한 방법이지만, 회전하고 방향을 제거하는 태생상 유용성이 떨어진다. **매니폴드 학습** 알고리즘, 시각화 알고리즘들은 훨씬 봅잡한 맵핑을 만들어 더 나은 시각화를 제공한다. 특별히 t-SNE 알고리즘을 아주 많이 사용한다.\n",
        "\n",
        "\n",
        "\\\n",
        "매니폴드 학습 알고리즘은 그 목정이 시각화라 3개 이상의 특성을 뽑은 경우는 거의 없다. 즉. 테스트 셋에서는 적용할 수 없고, 단지 훈현했던 데이터만 변환할 수 있다. 지도학습용으로는 거의 시용하지 않는다.\n",
        "t-SNE는 멀리 떨어진 포인트와 거리를 보존하는 것보다. 가까이 있는 포인트에 더 많은 비중으 둔다. 다시 말해, 이웃 데이터 포인트에 대한 정보를 보존하려 노력한다.\n",
        "\n",
        "\\\n",
        "다음은 손글씨 숫자 데이터셋에 t-SNE 매니폴드 학습을 적용해 보겠다. 데이터셋의 각 포인트는 0에서 9 사이의 손글씨 숫자를 표현한 8X8 크기의 흑백 이미지다."
      ],
      "metadata": {
        "id": "-rm1u_kIhkBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(10, 5), subplot_kw={'xticks':(), 'yticks':()})\n",
        "for ax, img in zip(axes.ravel(), digits.images):\n",
        "  ax.imshow(img)\n"
      ],
      "metadata": {
        "id": "NzDQ9P0R5qR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA를 사용해 데이터를 2차원으로 축소해 시각화하겠다. 차음 두 개의 주성분을 이용해 그래프를 그리고\n",
        "# 각 샘플을 해당하는 클래스의 숫자로 나타냈다.\n",
        "\n",
        "# PCA 모델을 생성\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(digits.data)\n",
        "# 처음 두 개으 주성분으로 숫자 데이터를 변환\n",
        "digits_pca = pca.transform(digits.data)\n",
        "colors = [\"#476A2A\",\"#7851B8\",\"#BD3430\",\"#4A2D4E\",\"#875525\",\"#A83683\",\"#4E655E\",\"#853541\",\"#3A3120\",\"#535D8E\" ]\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.xlim(digits_pca[:,0].min(), digits_pca[:,0].max())\n",
        "plt.ylim(digits_pca[:,1].min(), digits_pca[:,1].max())\n",
        "# 숫자 텍스트를 이용해 산점도를 그린다.\n",
        "for i in range(len(digits.data)):\n",
        "  plt.text(digits_pca[i, 0], digits_pca[i, 1], str(digits.target[i]),\n",
        "           color = colors[digits.target[i]], fontdict={'weight':'bold','size': 9})\n",
        "plt.xlabel(\"pcomp 1\")\n",
        "plt.ylabel(\"pcomp 2\")\n",
        "  \n",
        "# 0,6,4 는 잘 불리되었으나 다른 숫자들은 대부분 중첩된 부분이 있다"
      ],
      "metadata": {
        "id": "wlhLLsvQ6fn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t-SNE와 비교\n",
        "\n",
        "# 사이킷런 1.2 버전엔 TSNE의 init 매개변수 기본값이 'random'에서 'pca'로 바뀌고\n",
        "# learning_rate 매개변수 기본값이 200.0에서 'auto'로 바뀔 예정\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "tsne = TSNE(random_state=42)\n",
        "# TSNE에 transform 메서드가 없으므로 대신 fit_tranform을 사용\n",
        "digits_tsne = tsne.fit_transform(digits.data)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.xlim(digits_tsne[:,0].min(), digits_tsne[:,0].max() + 1)\n",
        "plt.ylim(digits_tsne[:,1].min(), digits_tsne[:,1].max() + 1)\n",
        "\n",
        "for i in range(len(digits.data)):\n",
        "  plt.text(digits_tsne[i, 0], digits_tsne[i, 1], str(digits.target[i]),\n",
        "           color = colors[digits.target[i]], fontdict={'weight':'bold','size': 9})\n",
        "\n",
        "plt.xlabel(\"t-SNE feature 1\")\n",
        "plt.ylabel(\"t-SNE feature 2\")"
      ],
      "metadata": {
        "id": "0Vk0cwKE_Tft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모든 클래스가 확실히 잘 구분되었다. 1과 9는 조금 나뉘었지만 대부분의 숫자는 하나의 그룹으로 모여있다.\n",
        "\n",
        "t-SNE는 매개변수를 약간 조정해야 하지만 기본값으로도 잘 작동하는 경우가 많다.\n",
        "perplexity 와 _exaggeration를 변경해볼 수 있지만 보통 효과는 크지 않다.\n",
        "\n",
        "\\\n",
        "## 3.5 군 집\n",
        "\n",
        "군집은 데이터셋을 클러스터라는 그룹으로 나누는 작업니다. 한 클러스트 안 데이터 포인트끼리는 매우 비숫하고 다른 클러스터의 데이터 포인트와는 구분되도록 데이터를 나누는 것이 목표이다.\n",
        "\n",
        "분류 알고리즘과 비슷하게 군집 알고리즘은 각 데이터 포인트가 얼느 클러스터에 속하는지 할당 또는 예측한다.\n",
        "\n",
        "\\\n",
        "#### 3.5.1 k-평균 군집\n",
        "\n",
        "k-평균 군집은 가장 간단하고 또 널리 사용하는 군집 알고리즘이다.이 알고리즘은 데이터의 어떤 영역을 대표하는 클러스터 중심을 찾는다."
      ],
      "metadata": {
        "id": "6NQzmdSuBtbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mglearn.plots.plot_kmeans_algorithm()"
      ],
      "metadata": {
        "id": "lnsWL1XhBtM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위에서 학습시킨 클러스터 중심의 경계이다\n",
        "mglearn.plots.plot_kmeans_boundaries()"
      ],
      "metadata": {
        "id": "CjGEQkwVFHKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KMeans 의 객체생성 찾고자하는 클러스터의 수를 지정\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# 인위적으로 2차원 데이터를 생성\n",
        "X, y = make_blobs(random_state=1)\n",
        "\n",
        "# 군집 모델을 만든다.\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "kmeans.fit(X)"
      ],
      "metadata": {
        "id": "fv9WxIQkFSt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"클러스터 레이블:\\n{}\".format(kmeans.labels_))\n",
        "\n",
        "# 3개로 지정했기 때문에 0~2까지 생성"
      ],
      "metadata": {
        "id": "J22Rkk5sGDsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측\n",
        "print(kmeans.predict(X))"
      ],
      "metadata": {
        "id": "f8fT_32_GRXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "알고리즘이 우리에게 주는 정보에서 숫자는 의미가 없다. 한명의 사진을 3가지로 나눌 수도 있다. 그저 동일한 숫자는 모두 서로 비슷하다는 의미이다. 이는 사진을 직접봐야 한다.\n",
        "2차원 예제에서도 0,1로 지정되는 건 중요하지 않다. 초기화를 무작위호 하기 때문에 알고리즘을 다시 실행하면 클러스터의 번호가 다르게 부여될 수 있다"
      ],
      "metadata": {
        "id": "MjXkXrBNHKlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프를 그리고 cluster_centers_ 속성에 저장된 클러스터 중심을 삼각형으로 표시한다.\n",
        "mglearn.discrete_scatter(X[:, 0], X[:, 1], kmeans.labels_, markers='o')\n",
        "mglearn.discrete_scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], [0, 1, 2],\n",
        "                         markers='^', markeredgewidth=2)"
      ],
      "metadata": {
        "id": "0azltS6OHIFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클러스터 수를 늘리거나 줄여봄\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "# 두 개의 클러스터 중심을 사용한다.\n",
        "kmeans = KMeans(n_clusters=2)\n",
        "kmeans.fit(X)\n",
        "assignments = kmeans.labels_\n",
        "mglearn.discrete_scatter(X[:, 0], X[:, 1], assignments, ax=axes[0])\n",
        "\n",
        "# 다섯 개의 클러스터 중심을 사용한다.\n",
        "kmeans = KMeans(n_clusters=5)\n",
        "kmeans.fit(X)\n",
        "assignments = kmeans.labels_\n",
        "\n",
        "mglearn.discrete_scatter(X[:, 0], X[:, 1], assignments, ax=axes[1])"
      ],
      "metadata": {
        "id": "ec6P8LaGIlZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "k 평균알고리즘의 한계\n",
        "\n",
        "k-평균 알고리즘은 비교적 간단한 형태를 구분할 수 있다. 또한 k-평균은 모든 틀러스터의 반경이 똑같다고 가정한다. 그래서 클러스터 중심 사이의 정확히 중간에 경계를 그리는데, 이는 가끔 예상치 않는 결과를 만들기도 한다."
      ],
      "metadata": {
        "id": "k7UhMwcPJ9y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_varied, y_varied = make_blobs(n_samples=200, cluster_std=[1.0, 2.5, 0.5], random_state=170)\n",
        "y_pred = KMeans(n_clusters=3, random_state=0).fit_predict(X_varied)\n",
        "mglearn.discrete_scatter(X_varied[:, 0], X_varied[:, 1], y_pred)\n",
        "plt.legend(['cluster 0', 'cluster 1', 'cluster 2'], loc='best')\n",
        "plt.xlabel('feature 0')\n",
        "plt.ylabel('feature 1')"
      ],
      "metadata": {
        "id": "uKDPRuthJ72g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 무작위로 클러스터 데이터를 생성\n",
        "X, y = make_blobs(random_state=170, n_samples=600)\n",
        "rng = np.random.RandomState(74)\n",
        "# 데이터가 길게 늘어지도록 변경\n",
        "transformation = rng.normal(size=(2,2))\n",
        "X = np.dot(X, transformation)\n",
        "\n",
        "# 세 개의 클러스터로 데이터에 KMeans 알고리즘을 적용한다.\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "kmeans .fit(X)\n",
        "y_pred = kmeans.predict(X)\n",
        "\n",
        "# 클러스터 할당과 클러스터 중심을 나타낸다.\n",
        "mglearn.discrete_scatter(X[:,0], X[:,1], kmeans.labels_, markers='o')\n",
        "mglearn.discrete_scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], [0,1,2], markers='^', markeredgewidth=2)\n",
        "plt.xlabel(\"feature 0\")\n",
        "plt.ylabel(\"feature 1\")"
      ],
      "metadata": {
        "id": "b19ov8IWMDdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "원형이 아닌 클러스터는 구분하지 못한다.\n",
        "\\\n",
        "클러스터가 2장에서 본 two_moons 데이터처럼 더 복잡한 형태라면 k-평균의 성능이 더 나빠진다."
      ],
      "metadata": {
        "id": "CmAs9yWFN2Yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# two_moons 데이터를 생성한다. 이번에는 노이즈를 조금만 넣는다.\n",
        "X, y = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
        "\n",
        "# 두 개의 클러스터로 데이터에 KMeans 알고리즘을 적용한다.\n",
        "kmeans = KMeans(n_clusters=2)\n",
        "kmeans.fit(X)\n",
        "y_pred = kmeans.predict(X)\n",
        "\n",
        "# 클러스터 할당과 클러스터 중심을 표시한다.\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap=mglearn.cm2, s=60, edgecolors='k')\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n",
        "            marker= \"^\",c=[mglearn.cm2(0), mglearn.cm2(1)], s=100, linewidth=2,edgecolors='k')\n",
        "plt.xlabel(\"feature 0\")\n",
        "plt.ylabel(\"feature 1\")"
      ],
      "metadata": {
        "id": "KATRC_bCME_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 백터 양자화 또는 분해 메서드로서의 k-평균\n",
        "\n",
        "PCA, NMF, k-평균은 모두 분해 알고리즘이다.\n",
        "PCA, NMF는 모두 데이터 포인트를 어떤 성분의 합으로 표현한다.\n",
        "반면, k-평균은 하나의 성분으로 표현한다. 이렇게 각 포인트가 하나의 성분으로 분해되는 관점으로 보는 것을 벡터 양자화 라고 한다.\n",
        "\n",
        "\\\n",
        "다음은 PCA, NMF, k-평균에서 추출한 성분과 100개의 성분으로 테스트 셋의 얼국을 재구성 한 것을 나란히 비교해볼 것이다. k-평균의 경우 재구성은 훈련셋에서 찾은 가장 가까운 클러스터의 중심이다."
      ],
      "metadata": {
        "id": "_fJlNofgRRKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_people, y_people, stratify=y_people, random_state=42)\n",
        "nmf = NMF(n_components=100, init='nndsvd', random_state=0, max_iter=1000, tol=1e-2)\n",
        "nmf.fit(X_train)\n",
        "pca = PCA(n_components=100, random_state=0)\n",
        "pca.fit(X_train)\n",
        "kmeans = KMeans(n_clusters=100, random_state=0)\n",
        "kmeans.fit(X_train)\n",
        "\n",
        "X_reconstructed_pca = pca.inverse_transform(pca.transform(X_test))\n",
        "X_reconstructed_kmeans = kmeans.cluster_centers_[kmeans.predict(X_test)]\n",
        "X_reconstructed_nmf = np.dot(nmf.transform(X_test), nmf.components_)\n"
      ],
      "metadata": {
        "id": "cvagNz7hScPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 4, figsize=(12,12), subplot_kw={'xticks': (), 'yticks': ()})\n",
        "fig.suptitle('extraction of components')\n",
        "for ax, comp_kmeans, comp_pca, comp_nmf in zip(\n",
        "    axes.T, kmeans.cluster_centers_, pca.components_, nmf.components_):\n",
        "  ax[0].imshow(comp_kmeans.reshape(image_shape))\n",
        "  ax[1].imshow(comp_pca.reshape(image_shape), cmap='viridis')\n",
        "  ax[2].imshow(comp_nmf.reshape(image_shape))\n",
        "\n",
        "axes[0,0].set_ylabel(\"kmeans\")\n",
        "axes[1,0].set_ylabel(\"pca\")\n",
        "axes[2,0].set_ylabel(\"nmf\")\n",
        "\n",
        "# 재구성\n",
        "fig, axes = plt.subplots(4, 5, figsize=(12,12), subplot_kw={'xticks': (), 'yticks': ()})\n",
        "\n",
        "fig.suptitle('reconstitution')\n",
        "for ax, orig, rec_kmeans, rec_pca, rec_nmf in zip(\n",
        "    axes.T, X_test,X_reconstructed_kmeans, X_reconstructed_pca, X_reconstructed_nmf):\n",
        "  ax[0].imshow(orig.reshape(image_shape))\n",
        "  ax[1].imshow(rec_kmeans.reshape(image_shape))\n",
        "  ax[2].imshow(rec_pca.reshape(image_shape))\n",
        "  ax[3].imshow(rec_nmf.reshape(image_shape))\n",
        "\n",
        "axes[0,0].set_ylabel(\"origin\")\n",
        "axes[1,0].set_ylabel(\"kmeans\")\n",
        "axes[2,0].set_ylabel(\"pca\")\n",
        "axes[3,0].set_ylabel(\"nmf\")\n"
      ],
      "metadata": {
        "id": "DIJPnm-vMFXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bnskgzLiMFge"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}